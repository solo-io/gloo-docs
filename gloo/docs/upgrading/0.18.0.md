---
title: Upgrading to 0.18.0
weight: 1
---

# Upgrading to 0.18.0 on Kubernetes
In Gloo 0.18.0, we updated the Gateway API to support managing Envoy TCP (L4) routing configuration in addition to existing HTTP/S (L7). This required making a non-backwards compatible change to the Gateway CRD in Gloo. 

Due to limited support for CRD versioning in older versions of Kubernetes (we cannot assume our customers run Kubernetes 1.13+), we implemented this change with a new Gateway v2 CRD. Gloo 0.18.0+ will no longer install the old Gateway CRD or controller.  

This guide documents a process for safely upgrading Gloo to 0.18.0, with an emphasis on avoiding downtime while shifting traffic to the new Gateway implementation. 

## Upgrade Steps
### 1. Install Gloo v0.18.0 with the `upgrade` flag
If installing with `glooctl`, provide the `--upgrade` flag. If installing with Helm, set `upgrade: true` in the values file. 

The v0.18.0 installation manifest creates two new deployments in Kubernetes, `gateway-v2` and `gateway-proxy-v2`. 

By providing the upgrade flag, the manifest includes a Kubernetes Job that will automatically create new Gateway v2 CRDs based on the contents of the Gateway v1 CRDs. This ensures the new `gateway-v2` pod will maintain the same configuration as the original gateway, and the Envoy instance running in `gateway-proxy-v2` will be configured correctly. 

This **does not** modify or delete the existing Gateway v1 CRD(s), nor the deployments for `gateway` and `gateway-proxy`. In a later step, after traffic has been shifted to `gateway-proxy-v2`, these can be safely deleted. 

### 2. Verify Gateway v2 is healthy
First, make sure that the `gateway-v2` and `gateway-proxy-v2` pods are ready. 

The `gateway-proxy-v2` configuration can be tested. 
* Run `glooctl get proxy` and verify that the `gateway-proxy-v2` status is `ACCEPTED`. 
* Test traffic against `gateway-proxy-v2` to ensure it behaves similar to `gateway-proxy`
	This can be done with port-forwarding: `kubectl port-forward -n gloo-system deployment/gateway-proxy-v2 8080`
	Or by setting up a new service / ingress manually for testing. 

### 3. Migrate traffic to Gateway v2
Prior to upgrading, all traffic was being routed through the Envoy instance inside `gateway-proxy`. Now we can migrating traffic from `gateway-proxy` to `gateway-proxy-v2`. 

The upgrade to Gloo 0.18.0 added a selector to the `gateway-proxy` service in Kubernetes. By patching the `gateway-proxy-v2` deployment, we can start sending half of the traffic to the new proxy. Run `kubectl edit deployment -n gloo-system gateway-proxy-v2`, and update in the spec `disabled` to false. 

Once you are satisfied with traffic on Gateway v2, you can disable the `gateway-proxy` v1 deployment: `kubectl edit deployment -n gloo-system gateway-proxy` and set `disabled` to true. 

Verify that all traffic is successfully routed to `gateway-proxy-v2`.

### 4. Delete old Gateway v1 resources
Once all of the traffic is being routed through `gateway-proxy-v2`, the Gateway v1 resources can be safely deleted. 

* Remove Gateway v1 deployments with this command:
`kubectl delete -n gloo-system deployments/gateway deployments/gateway-proxy`
* Remove Gateway v1 CRDs with this command: 
`kubectl delete gateway.v1.gateway.solo.io -n gloo-system --all`

## Notes

### Upgrading Gateway CRDs in Git
If you are doing a GitOps workflow and have Gateway v1 CRDs in a git repository, those will need to be updated. Once upgraded to 0.18.0, the Gateway v2 CRDs can be saved to the Git repository, replacing the Gateway v1 CRDs. Alternative, the Gateway CRDs in git can be manually fixed and the group updated. Please contact us in Slack if you'd like help with this. 

### Kubernetes CRD upgrade support
In the future, we intend to utilize Kubernetes schemas and conversion webhooks, first introduced in Kubernetes 1.13, to facilitate better support around CRD versioning. However, at this time we must support older versions of Kubernetes, and so our upgrade process does not rely on those features. 

### More sophisticated traffic shifting
It may not be desirable to shift traffic 0 -> 50/50 -> 100% -- a more sophisticated approach may be preferred. We don't currently have support for this as part of this upgrade, but it is an area we'd like to improve and please contact us in slack if you'd like to explore that. 
